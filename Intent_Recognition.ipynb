{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "bnDK0OffbFez"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np\n",
        "import random\n",
        "import json\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y_2HY5rubLHA",
        "outputId": "8644ba95-7ab6-4c66-912a-6ad9156328d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['intents'])\n",
            "<class 'list'>\n",
            "22\n",
            "dict_keys(['intent', 'text', 'responses', 'extension', 'context', 'entityType', 'entities'])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'intent': 'SelfAware',\n",
              " 'text': ['Can you prove you are self-aware',\n",
              "  'Can you prove you are self aware',\n",
              "  'Can you prove you have a conscious',\n",
              "  'Can you prove you are self-aware please',\n",
              "  'Can you prove you are self aware please',\n",
              "  'Can you prove you have a conscious please',\n",
              "  'prove you have a conscious'],\n",
              " 'responses': ['That is an interesting question, can you prove that you are?',\n",
              "  'That is an difficult question, can you prove that you are?',\n",
              "  'That depends, can you prove that you are?'],\n",
              " 'extension': {'function': '', 'entities': False, 'responses': []},\n",
              " 'context': {'in': '', 'out': '', 'clear': False},\n",
              " 'entityType': 'NA',\n",
              " 'entities': []}"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "\n",
        "\n",
        "with open('Intent.json', 'r') as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "print(data.keys())\n",
        "print(type(data['intents']))\n",
        "print(len(data['intents']))\n",
        "print(data['intents'][0].keys())\n",
        "data['intents'][-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "VsYUYhGxcpjL"
      },
      "outputs": [],
      "source": [
        "def clean(line):\n",
        "\tcleaned_line = ''\n",
        "\tfor char in line:\n",
        "\t\tif char.isalpha():\n",
        "\t\t\tcleaned_line += char\n",
        "\t\telse:\n",
        "\t\t\tcleaned_line += ' '\n",
        "\tcleaned_line = ' '.join(cleaned_line.split())\n",
        "\treturn cleaned_line\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "34p036yHeBpu",
        "outputId": "8c5d0553-c37e-4365-c24e-44403ea94004"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'hello who are you and what are you doing hauau'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "clean('hello who are you?and what are you doing?!....hauau13341==12@')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "iT9krItbeD2W"
      },
      "outputs": [],
      "source": [
        "#list of intents\n",
        "intents = []\n",
        "unique_intents = []\n",
        "#all text data to create a corpus\n",
        "text_input= []\n",
        "#dictionary mapping intent with appropriate response\n",
        "response_for_intent = {}\n",
        "for intent in data['intents']:\n",
        "\t#list of unique intents\n",
        "\tif intent['intent'] not in unique_intents:\n",
        "\t\tunique_intents.append(intent['intent'])\n",
        "\tfor text in intent['text']:\n",
        "\t\t#cleaning is done before adding text to corpus\n",
        "\t\ttext_input.append(clean(text))\n",
        "\t\tintents.append(intent['intent'])\n",
        "\tif intent['intent'] not in response_for_intent:\n",
        "\t\tresponse_for_intent[intent['intent']] = []\n",
        "\tfor response in intent['responses']:\n",
        "\t\tresponse_for_intent[intent['intent']].append(response)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rGQa6jKhejg-",
        "outputId": "8631693e-5fe6-48ef-bcb1-e1b24ffbbbb8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Intent : Greeting\n",
            "Number of Intent: 143\n",
            "Sample Input: Hi\n",
            "Length of text_input: 143\n",
            "Sample Response:  ['Hi human, please tell me your GeniSys user', 'Hello human, please tell me your GeniSys user', 'Hola human, please tell me your GeniSys user']\n"
          ]
        }
      ],
      "source": [
        "print(\"Intent :\",intents[0])\n",
        "print(\"Number of Intent:\",len(intents))\n",
        "print(\"Sample Input:\", text_input[0])\n",
        "print('Length of text_input:',len(text_input))\n",
        "print(\"Sample Response: \", response_for_intent[intents[0]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rpS1rvI7elF6",
        "outputId": "281fcd9d-801e-4611-de66-6b832545e756"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of Input Sequence: (143, 9)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0,  0,  0,  0,  0,  0,  0,  0, 52],\n",
              "       [ 0,  0,  0,  0,  0,  0,  0, 52, 53],\n",
              "       [ 0,  0,  0,  0,  0,  0,  0,  0, 68],\n",
              "       [ 0,  0,  0,  0,  0,  0,  0,  0, 39],\n",
              "       [ 0,  0,  0,  0,  0,  0,  0, 39, 53],\n",
              "       [ 0,  0,  0,  0,  0,  0,  0,  0, 69],\n",
              "       [ 0,  0,  0,  0,  0,  0,  0, 69, 53],\n",
              "       [ 0,  0,  0,  0,  0, 29, 40,  3, 21],\n",
              "       [ 0,  0,  0,  0,  0,  0, 41,  3, 21],\n",
              "       [ 0,  0,  0,  0,  0,  0,  7, 13, 21],\n",
              "       [ 0,  0,  0,  0,  0,  0, 30,  3, 21],\n",
              "       [ 0,  0,  0,  0,  0, 29, 40,  3, 22],\n",
              "       [ 0,  0,  0,  0,  0,  0, 41,  3, 22],\n",
              "       [ 0,  0,  0,  0,  0,  0,  7, 13, 22],\n",
              "       [ 0,  0,  0,  0,  0,  0, 30,  3, 22],\n",
              "       [ 0,  0,  0,  0,  0,  0, 31,  5,  2],\n",
              "       [ 0,  0,  0,  0,  0, 52, 31,  5,  2],\n",
              "       [ 0,  0,  0,  0,  0, 39, 31,  5,  2],\n",
              "       [ 0,  0,  0,  0,  0, 68, 31,  5,  2],\n",
              "       [ 0,  0,  0,  0,  0, 31,  5,  2, 54]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "tokenizer = Tokenizer(filters='',oov_token='<unk>')\n",
        "tokenizer.fit_on_texts(text_input)\n",
        "sequences = tokenizer.texts_to_sequences(text_input)\n",
        "padded_sequences = pad_sequences(sequences, padding='pre')\n",
        "print('Shape of Input Sequence:',padded_sequences.shape)\n",
        "padded_sequences[:20]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rbsosFOyfxUi",
        "outputId": "074556b7-6bef-4f2d-a1dd-fdc528461dcb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Intents : 22\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'Greeting',\n",
              " 1: 'GreetingResponse',\n",
              " 2: 'CourtesyGreeting',\n",
              " 3: 'CourtesyGreetingResponse',\n",
              " 4: 'CurrentHumanQuery',\n",
              " 5: 'NameQuery',\n",
              " 6: 'RealNameQuery',\n",
              " 7: 'TimeQuery',\n",
              " 8: 'Thanks',\n",
              " 9: 'NotTalking2U',\n",
              " 10: 'UnderstandQuery',\n",
              " 11: 'Shutup',\n",
              " 12: 'Swearing',\n",
              " 13: 'GoodBye',\n",
              " 14: 'CourtesyGoodBye',\n",
              " 15: 'WhoAmI',\n",
              " 16: 'Clever',\n",
              " 17: 'Gossip',\n",
              " 18: 'Jokes',\n",
              " 19: 'PodBayDoor',\n",
              " 20: 'PodBayDoorResponse',\n",
              " 21: 'SelfAware'}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "intent_to_index = {}\n",
        "categorical_target = []\n",
        "index = 0\n",
        "\n",
        "for intent in intents:\n",
        "\tif intent not in intent_to_index:\n",
        "\t\tintent_to_index[intent] = index\n",
        "\t\tindex += 1\n",
        "\tcategorical_target.append(intent_to_index[intent])\n",
        "\n",
        "num_classes = len(intent_to_index)\n",
        "print('Number of Intents :',num_classes)\n",
        "\n",
        "# Convert intent_to_index to index_to_intent\n",
        "index_to_intent = {index: intent for intent, index in intent_to_index.items()}\n",
        "index_to_intent\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ubMuO4g0fPIX",
        "outputId": "5480c24f-f57a-4d9a-9758-56c84b6f4ce6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of Ca (143, 22)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "categorical_vec = tf.keras.utils.to_categorical(categorical_target,num_classes=num_classes)\n",
        "\n",
        "print('Shape of Ca',categorical_vec.shape)\n",
        "categorical_vec[:5]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "YBKpa7uogvxi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f72bb16e-60b7-447e-b0f1-538e39c50189"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Dimension :22,\n",
            "Output Dimension :22\n"
          ]
        }
      ],
      "source": [
        "epochs=100\n",
        "embed_dim=300\n",
        "lstm_num=50\n",
        "output_dim=categorical_vec.shape[1]\n",
        "input_dim=len(unique_intents)\n",
        "print(\"Input Dimension :{},\\nOutput Dimension :{}\".format(input_dim,output_dim))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "\ttf.keras.layers.Embedding(len(tokenizer.word_index) + 1, embed_dim),\n",
        "\ttf.keras.layers.Bidirectional(tf.keras.layers.LSTM(lstm_num, dropout=0.1)),\n",
        "\ttf.keras.layers.Dense(lstm_num, activation='relu'),\n",
        "\ttf.keras.layers.Dropout(0.4),\n",
        "\ttf.keras.layers.Dense(output_dim, activation='softmax')\n",
        "])\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(0.001)\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "WBSPcU7xX3sa",
        "outputId": "b6ef42b9-7079-4d55-d8df-baeddcb02645"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)              │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m)      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(padded_sequences, categorical_vec, epochs=epochs, verbose=0)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJ2AHh14X5NZ",
        "outputId": "ef67fdcf-63e9-4e4a-dcf3-52d0becd77bf"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7af3aa024d90>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_text_inputs = [\"Hello\",\n",
        "\t\t\t\t\t\"my name is adam\",\n",
        "\t\t\t\t\t\"how are you?\",\n",
        "\t\t\t\t\t\"can you guess my name?\",\n",
        "\t\t\t\t\t\"Do you get me\",\"Adios\"]\n",
        "\n",
        "test_intents = [\"Greeting\",\n",
        "\t\t\t\t\"GreetingResponse\",\n",
        "\t\t\t\t\"CourtesyGreeting\",\n",
        "\t\t\t\t\"CurrentHumanQuery\",\n",
        "\t\t\t\t\"UnderstandQuery\",\n",
        "\t\t\t\t\"GoodBye\"]\n",
        "\n",
        "test_sequences = tokenizer.texts_to_sequences(test_text_inputs)\n",
        "test_padded_sequences = pad_sequences(test_sequences, padding='pre')\n",
        "test_labels = np.array([unique_intents.index(intent) for intent in test_intents])\n",
        "test_labels = tf.keras.utils.to_categorical(test_labels, num_classes=num_classes)\n",
        "loss, accuracy = model.evaluate(test_padded_sequences, test_labels)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wVjevz0UX7dd",
        "outputId": "63e712f7-77ff-49d9-8e26-70c08efff4ee"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 536ms/step - accuracy: 0.6667 - loss: 1.4259\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def response(sentence):\n",
        "\tsent_tokens = []\n",
        "\t# Split the input sentence into words\n",
        "\twords = sentence.split()\n",
        "\t# Convert words to their corresponding word indices\n",
        "\tfor word in words:\n",
        "\t\tif word in tokenizer.word_index:\n",
        "\t\t\tsent_tokens.append(tokenizer.word_index[word])\n",
        "\t\telse:\n",
        "\t\t\t# Handle unknown words\n",
        "\t\t\tsent_tokens.append(tokenizer.word_index['<unk>'])\n",
        "\tsent_tokens = tf.expand_dims(sent_tokens, 0)\n",
        "\t#predict numerical category\n",
        "\tpred = model(sent_tokens)\n",
        "\t#category to intent\n",
        "\tpred_class = np.argmax(pred.numpy(), axis=1)\n",
        "\t# random response to that intent\n",
        "\treturn random.choice(\n",
        "\t\tresponse_for_intent[index_to_intent[pred_class[0]]]), index_to_intent[pred_class[0]]\n"
      ],
      "metadata": {
        "id": "IA36j9NFYECE"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Note: Enter 'quit' to break the loop.\")\n",
        "while True:\n",
        "\tquery = input('You: ')\n",
        "\tif query.lower() == 'quit':\n",
        "\t\tbreak\n",
        "\tbot_response, typ = response(query)\n",
        "\tprint('AI: {} -- TYPE: {}'.format(bot_response, typ))\n",
        "\tprint()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5RXqfQGsYFsY",
        "outputId": "db55fcb0-f460-4ee1-d4d1-9daef0f54f65"
      },
      "execution_count": 21,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: Enter 'quit' to break the loop.\n",
            "You: hello \n",
            "AI: Hola human, please tell me your GeniSys user -- TYPE: Greeting\n",
            "\n",
            "You: can you help me?\n",
            "AI: That depends, can you prove that you are? -- TYPE: SelfAware\n",
            "\n",
            "You: tell me something\n",
            "AI: Please look at the camera -- TYPE: WhoAmI\n",
            "\n",
            "You: quit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yuxG_JirZq2Q"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}